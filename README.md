# Поиск руководств по поисковому запросу

## Постановка задачи
Фирма [Моё дело](https://www.moedelo.org/) предоставляет услуги бухгалтерского обслужвания
и размещает на своём сайте "базу знаний" для предпренимателей, содержащую большое количество 
руководств по бухгалтерскому и налоговому учёту. Базе знаний не хватает поисковой системы.
**Задача - разработать систему поиска документов наиболее релевантных запросу пользователя.**

*Задача ставится как задача ранжирования: нужно возвращать N наиболее релевантных 
запросу документов*.

## Возможные решения
1. Использовать простые методы на основе сходства Жаккара, алгоритма шилингов, расстояния Левенштейна.
   **Плюс** - простота реализации. **Минус** - слабые результаты. Подробнее в [статье](https://www.pinecone.io/learn/semantic-search/).
1. Использовать готовый поисковый движок, например [Tantivy](https://github.com/quickwit-oss/tantivy)
   или [Apache Lucene](https://lucene.apache.org/). **Плюс:** поиск выполняется быстро даже 
   на очень большом объёме текстов. **Минус:** может не учитываться семантика слов, поэтому
   поисковый движок может не учитывать контекст. Подробнее в [статье](https://habr.com/ru/articles/545634/).
1. Использовать модели машинного обучения, 
   [создающую эмбединги из текстов](https://www.sbert.net/examples/applications/computing-embeddings/README.html), 
   например 
   [Sentence-BERT](https://www.sbert.net/) или
   [Doc2vec](https://radimrehurek.com/gensim/models/doc2vec.html) из [Gensim](https://radimrehurek.com/gensim/).
   В этом случае задачу можно формулировать либо как задачу 
   [семантического поиска](https://www.sbert.net/examples/applications/semantic-search/README.html), либо
   как задачу [семантического текстового сходства](https://www.sbert.net/docs/usage/semantic_textual_similarity.html).
   **Плюс:** решение учтёт семантику и контекст запроса. **Минус:** может работать очень медленно на большом
   корпусе текстов.
   
## Предлагаемое решение
Предлагается использовать вариант с созданием эмбедингов из текстов.
Ниже приведены предполагаемые шаги по разработке первого прототипа модели.
1. Использовать предобученную BERT или DistilBERT, так как есть опыт её использования, но можно 
   рассмотреть и другие.
3. Дообучить модель на имеющихся текстах.
4. Разбить тексты на части пригодные для обработки BERT. Для начала можно попробовать разбивку
   без пересечения.
5. Сделать эмбединги из каждой части с помощью библиотеки [Sentence-BERT](https://www.sbert.net/). В итоге,
   каждый фрагмент текста можно будет представить точкой в многомерном пространстве (вектором размерности 
   эмбединга), а каждое полное руководство будет образовывать облако таких точек. Каждое облако будет 
   образовывать свой кластер или класс с меткой равной ID-текста. 
6. С помощью дообученного BERT cделать эмбединг из запроса пользователя. 
7. Решать задачу ранжирования: считать, что наиболее релевантный текст - тот, "чьё облако ближе всего" 
   к вектору, полученному из запроса пользователя. Можно рассмотреть альтернативное решение: искать
   фрагмент текста (только один эмбединг) наиболее похожий на запрос пользователя и считать самым
   релевантным руководство, частью которого я вляется этот фрагмент.
10. Под вопросом остаётся оценка качества поисковой выдачи (результатов ранжирования). [Статья про
    метрики ранжирования](https://habr.com/ru/companies/econtenta/articles/303458/).

**Возможные проблемы:**
1. Опечатки пользователей, ошибки в исходных текстах (пока не обдумывал).
2. Низкая скорость работы модели.

## Вопросы
1. Каков реальный объём текстов? Есть ли требования к скорости работы модели?
2. Есть ли какое-либо базовое решение, с котороым можно будет сравнить прототип модели?
3. Есть ли гипотеза о том какую модель лучше использовать для создания эмбедингов: BERT,
   GPT или другие?
4. Как оценивать качество поисковой выдачи? Ранжирование - задача обучения с учителем, что
   предполагает наличие разметки. Будет ли разметка?
